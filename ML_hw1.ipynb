{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_hw1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdullah-Al-Arafat/CAP-5610-Machine-Learning/blob/master/ML_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UswAAhVvXbXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CAP 5610: Machine Learning** \n",
        "Home work 1"
      ]
    },
    {
      "metadata": {
        "id": "3MZ9JQOWR7QM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7GNhBIHSlmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load MNIST dataset from keras and preprocess the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "X_test = x_test.reshape(x_test.shape[0], -1)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nV7CAs0KVO9y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialization of parameters\n",
        "\n",
        "parameters = {'W' : np.zeros((X_train.shape[1], 1)),   # for problem 1 and 2\n",
        "             'b': np.zeros(1)}\n",
        "batch_size = 40\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQWuW0VJvbp6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Necessary functions for forward and back propagation, and loss calculation"
      ]
    },
    {
      "metadata": {
        "id": "KOYVpZpGseAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid (x):\n",
        "  y = 1/(1 + np.exp(-x))\n",
        "  return y\n",
        "\n",
        "def softmax(Z):\n",
        "  return np.exp(Z)/np.sum(np.exp(Z), axis = 1, keepdims= True)\n",
        "\n",
        "def d_sigmoid (x):   # differentiation of sigmoid function \n",
        "  y = sigmoid(x)*(1-sigmoid(x))\n",
        "  return y\n",
        "\n",
        "def forward_pro(X,parameters):\n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  y = sigmoid(np.dot(X, W) + b)\n",
        "  return y\n",
        "\n",
        "def forward_softmax(X, parameters):\n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  Z = np.dot(X, W) + b\n",
        "  y = softmax(Z)\n",
        "  return y\n",
        "\n",
        "def loss_cross(y, yest):\n",
        "  loss = - np.sum(y*np.log(yest)+(1-y)*np.log(1 - yest))/y.shape[0]\n",
        "  return loss\n",
        "\n",
        "def loss_mse (y, yest):\n",
        "  loss = np.sum((y-yest)*(y-yest))/y.shape[0]\n",
        "  return loss\n",
        "\n",
        "def loss_cc (y, yest): #catogorical cross entropy \n",
        "  loss = - np.sum(y*np.log(yest))/y.shape[0]\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHkVPEaSvSUs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 1:**\n",
        "***logistic regression with mean squared error loss***"
      ]
    },
    {
      "metadata": {
        "id": "q62H9HxXXZuW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_mse(X_train, Y_train, learning_rate, batch_size, parameters, epochs):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]  \n",
        "\n",
        "      y_est = forward_pro(X, parameters)   \n",
        "\n",
        "      loss = loss_mse(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*y_est*(1-y_est)*(y_est - Y) # dZ = A'*(A-Y) for mean square error\n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameters['W'] = W\n",
        "      parameters['b'] = b  \n",
        "  \n",
        "  return parameters\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPLlDFcslC0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run ten individual one vs all classifier for mean square error\n",
        "Parameter = {}\n",
        "for i in range(10):\n",
        "  Y = (y_train == i).reshape(-1,1)*1\n",
        "  Parameter[i] = model_mse(X_train, Y, learning_rate, batch_size, parameters, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFCFSaIFmR7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3dab92f9-b166-4469-896e-d9cfa59930f3"
      },
      "cell_type": "code",
      "source": [
        "# Accuracy of the classifiers \n",
        "for i in range (10):\n",
        "  Y_est = (forward_pro(X_test, Parameter[i])>0.5)*1\n",
        "  acc = np.sum((Y_est == (y_test == i).reshape(-1,1))*1)/y_test.shape[0]\n",
        "  print (\"Accuracy for %d vs all: %f\" %(i, acc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0 vs all: 0.893500\n",
            "Accuracy for 1 vs all: 0.878000\n",
            "Accuracy for 2 vs all: 0.888300\n",
            "Accuracy for 3 vs all: 0.890500\n",
            "Accuracy for 4 vs all: 0.893300\n",
            "Accuracy for 5 vs all: 0.902300\n",
            "Accuracy for 6 vs all: 0.895700\n",
            "Accuracy for 7 vs all: 0.890900\n",
            "Accuracy for 8 vs all: 0.894100\n",
            "Accuracy for 9 vs all: 0.905400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pS2YVraR3hTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 2:**  ***logistic regression with binary cross entropy loss*** "
      ]
    },
    {
      "metadata": {
        "id": "dEWXJkSb3se-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_cross(X_train, Y_train, learning_rate, batch_size,parameters, epochs):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]\n",
        "      \n",
        "      y_est = forward_pro(X, parameters)   \n",
        "\n",
        "      loss = loss_cross(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*(y_est - Y) # dZ = A - Y for cross entropy loss\n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameters['W'] = W\n",
        "      parameters['b'] = b\n",
        "      \n",
        "  \n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnGVk4Vo3r-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run ten individual one vs all classifier for binary cross entropy loss\n",
        "Parameter = {}\n",
        "for i in range(10):\n",
        "  Y = (y_train == i).reshape(-1,1)*1\n",
        "  Parameter[i] = model_cross(X_train, Y, learning_rate, batch_size, parameters, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weLUXiHiFVIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b59c7b94-ab1e-4f83-f737-ecceb9356225"
      },
      "cell_type": "code",
      "source": [
        "# Accuracy of the classifiers \n",
        "for i in range (10):\n",
        "  Y_est = (forward_pro(X_test, Parameter[i])>0.5)*1\n",
        "  acc = np.sum((Y_est == (y_test == i).reshape(-1,1))*1)/y_test.shape[0]\n",
        "  print (\"Accuracy for %d vs all: %f\" %(i, acc))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0 vs all: 0.828800\n",
            "Accuracy for 1 vs all: 0.813300\n",
            "Accuracy for 2 vs all: 0.823800\n",
            "Accuracy for 3 vs all: 0.825800\n",
            "Accuracy for 4 vs all: 0.836400\n",
            "Accuracy for 5 vs all: 0.838400\n",
            "Accuracy for 6 vs all: 0.831000\n",
            "Accuracy for 7 vs all: 0.832000\n",
            "Accuracy for 8 vs all: 0.829800\n",
            "Accuracy for 9 vs all: 0.955100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zalG8Sjy4oCt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 3:** ***softmax and categorical cross entropy loss***"
      ]
    },
    {
      "metadata": {
        "id": "DVCYDz6m4nak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_softmax(X_train, Y_train, learning_rate, batch_size, parameters, epochs):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]  \n",
        "\n",
        "      y_est = forward_softmax(X, parameters)   \n",
        "     \n",
        "      loss = loss_cc(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*(y_est - Y) \n",
        "      '''dzi = {ai - 1, if ith level is true. ai otherwise} \n",
        "      which vectorized as dZ = A-Y. dZ is divided by batch size for normalizing \n",
        "      '''  \n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameters['W'] = W\n",
        "      parameters['b'] = b     \n",
        "  \n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZjASYEAj7TbI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting labels(y) into one hot vector \n",
        "\n",
        "a = y_train\n",
        "Y = np.zeros((a.size, a.max()+1))\n",
        "Y[np.arange(a.size),a] = 1\n",
        "\n",
        "parameters_3 = {'W' : np.zeros((X_train.shape[1], 10)),\n",
        "             'b': np.zeros((1,10))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KaeIZhefIn0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Parameter = model_softmax(X_train, Y, learning_rate, batch_size, parameters_3, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrunrLyHQxIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7a985d7-fc21-4f2c-e9b0-42e008fca0eb"
      },
      "cell_type": "code",
      "source": [
        "y_est = forward_softmax(X_test, Parameter)\n",
        "Y_est = np.argmax(y_est, axis = 1)\n",
        "acc = np.sum(Y_est == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for softmax classifier: %f\" %acc)\n",
        "             "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for softmax classifier: 0.892100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vQZBxZTA7Uy7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 4:** ***Keras implementation ***"
      ]
    },
    {
      "metadata": {
        "id": "3bU8XL-6HtnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d0435bb1-63eb-48b9-8518-5555e4b38696"
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(10, activation='softmax', input_shape=(28 * 28,)))\n",
        "network.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1SaMUnqiHtdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# preprocessing of dataset\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "X_test = x_test.reshape(x_test.shape[0], -1)/255\n",
        "\n",
        "a = y_train\n",
        "Y_train = np.zeros((a.size, a.max()+1))\n",
        "Y_train[np.arange(a.size),a] = 1\n",
        "Y_train = Y_train\n",
        "\n",
        "b = y_test\n",
        "Y_test = np.zeros((b.size, b.max()+1))\n",
        "Y_test[np.arange(b.size),b] = 1\n",
        "Y_test = Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHjE9097fSto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import sgd\n",
        "\n",
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drIBrxgAfzht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "65b367bc-6f33-457c-a3fc-d26f2f5c5058"
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = network.fit(X_train, \n",
        "                      Y_train, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=40, \n",
        "                      validation_data=(X_test, Y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.8429 - acc: 0.8019 - val_loss: 0.5154 - val_acc: 0.8725\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.4849 - acc: 0.8750 - val_loss: 0.4223 - val_acc: 0.8904\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.4242 - acc: 0.8862 - val_loss: 0.3848 - val_acc: 0.8971\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3940 - acc: 0.8930 - val_loss: 0.3632 - val_acc: 0.9010\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3750 - acc: 0.8963 - val_loss: 0.3485 - val_acc: 0.9071\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3617 - acc: 0.8994 - val_loss: 0.3380 - val_acc: 0.9081\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3515 - acc: 0.9023 - val_loss: 0.3307 - val_acc: 0.9093\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3436 - acc: 0.9041 - val_loss: 0.3236 - val_acc: 0.9120\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3369 - acc: 0.9058 - val_loss: 0.3186 - val_acc: 0.9138\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3314 - acc: 0.9079 - val_loss: 0.3144 - val_acc: 0.9135\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3269 - acc: 0.9087 - val_loss: 0.3110 - val_acc: 0.9140\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.3227 - acc: 0.9094 - val_loss: 0.3079 - val_acc: 0.9166\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3191 - acc: 0.9107 - val_loss: 0.3051 - val_acc: 0.9153\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3159 - acc: 0.9120 - val_loss: 0.3021 - val_acc: 0.9164\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3130 - acc: 0.9130 - val_loss: 0.3012 - val_acc: 0.9169\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3104 - acc: 0.9135 - val_loss: 0.2983 - val_acc: 0.9169\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3082 - acc: 0.9140 - val_loss: 0.2969 - val_acc: 0.9189\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.3060 - acc: 0.9151 - val_loss: 0.2954 - val_acc: 0.9173\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.3040 - acc: 0.9154 - val_loss: 0.2940 - val_acc: 0.9176\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.3021 - acc: 0.9158 - val_loss: 0.2931 - val_acc: 0.9178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p41OHz2xn4IH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpxYY-6PYWpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 5:** ***Add a new feature as number of white areas in each images ***"
      ]
    },
    {
      "metadata": {
        "id": "rL334eui_bIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting the images into binary images\n",
        "\n",
        "X_train = ((x_train/255)>0.5)*1\n",
        "X_test = ((x_test/255)>0.5)*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ipe7Xyzr_wE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DFS algorithm for finding out the number of white regions in each black and white images  "
      ]
    },
    {
      "metadata": {
        "id": "pXtAvsuH_a67",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adj = {'row' : [-1, -1, -1, 0, 0, 1, 1, 1],\n",
        "          'column' : [-1, 0, 1, -1, 1, -1, 0, 1]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nODMzWIe_anC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def DFS_visit(V, adj, x, y, parent):\n",
        "    r = adj['row']\n",
        "    c = adj['column']\n",
        "    for i in range (len(r)):\n",
        "        p = x+r[i]\n",
        "        q = y + c[i]\n",
        "        if p >= 0 and q >= 0 and p < V.shape[0] and q < V.shape[1]:\n",
        "            if V[p,q] == 0:\n",
        "                if (p,q) not in parent:\n",
        "                    parent [p,q] = (x,y)\n",
        "                    DFS_visit(V, adj, p, q, parent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BR7ICut_aag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def DFS (V, adj):\n",
        "    x, y = V.shape\n",
        "    white_area = 0\n",
        "    parent = {}\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if (i,j) not in parent:\n",
        "                parent [i,j] = None\n",
        "                if V[i,j] == 0:\n",
        "                    DFS_visit(V, adj, i,j, parent)\n",
        "                    white_area += 1\n",
        "    return white_area"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnDfCqahCYpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training dataset with extra feature \n",
        "\n",
        "white_area = np.zeros((X_train.shape[0],1))\n",
        "\n",
        "for i in range (X_train.shape[0]):\n",
        "  X = X_train[i]\n",
        "  white_area[i, 0] = DFS(X,adj)\n",
        "  \n",
        "X_train_dfs = x_train.reshape(x_train.shape[0], -1)/255\n",
        "\n",
        "X_train_dfs = np.append(X_train_dfs, white_area/3, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAe3Fxg0BcpF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test dataset with extra feature \n",
        "\n",
        "white_area_t = np.zeros((X_test.shape[0],1))\n",
        "\n",
        "for i in range (X_test.shape[0]):\n",
        "  X = X_test[i]\n",
        "  white_area_t[i, 0] = DFS(X,adj)\n",
        "  \n",
        "X_test_dfs = x_test.reshape(x_test.shape[0], -1)/255\n",
        "\n",
        "X_test_dfs = np.append(X_test_dfs, white_area_t/3, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQW9PPchaf0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a008f54-ad20-4ebf-c25f-b08161f76f46"
      },
      "cell_type": "code",
      "source": [
        "X_train_dfs.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "Y7FGC-FlAKt8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parameters_dfs = {'W' : np.zeros((X_train_dfs.shape[1], 10)),\n",
        "             'b': np.zeros((1,10))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nt_C84VDa3Rn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Parameter_dfs = model_softmax(X_train_dfs, Y, learning_rate, batch_size, parameters_dfs, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xe3gif5bYo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4348b43-4fc8-4417-e23f-b8a0ac547772"
      },
      "cell_type": "code",
      "source": [
        "y_est = forward_softmax(X_test_dfs, Parameter_dfs)\n",
        "Y_est = np.argmax(y_est, axis = 1)\n",
        "acc = np.sum(Y_est == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for softmax classifier: %f\" %acc)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for softmax classifier: 0.895400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "70aS9u-ZbpyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}