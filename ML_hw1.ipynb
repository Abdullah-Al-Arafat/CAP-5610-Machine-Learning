{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_hw1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdullah-Al-Arafat/CAP-5610-Machine-Learning/blob/master/ML_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UswAAhVvXbXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CAP 5610: Machine Learning** \n",
        "Home work 1"
      ]
    },
    {
      "metadata": {
        "id": "3MZ9JQOWR7QM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6090b65e-5028-4c7a-803b-2b4cb449c1a0"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "y7GNhBIHSlmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d3169179-f4e6-4115-f503-899dfb5dd316"
      },
      "cell_type": "code",
      "source": [
        "# load MNIST dataset from keras and preprocess the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "X_test = x_test.reshape(x_test.shape[0], -1)/255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MQWuW0VJvbp6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Necessary functions for forward and back propagation, and loss calculation"
      ]
    },
    {
      "metadata": {
        "id": "KOYVpZpGseAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid (x):\n",
        "  y = 1/(1 + np.exp(-x))\n",
        "  return y\n",
        "\n",
        "def softmax(Z):\n",
        "  return np.exp(Z)/np.sum(np.exp(Z), axis = 1, keepdims= True)\n",
        "\n",
        "def d_sigmoid (x):   # differentiation of sigmoid function \n",
        "  y = sigmoid(x)*(1-sigmoid(x))\n",
        "  return y\n",
        "\n",
        "def forward_pro(X,parameters):\n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  y = sigmoid(np.dot(X, W) + b)\n",
        "  return y\n",
        "\n",
        "def forward_softmax(X, parameters):\n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  Z = np.dot(X, W) + b\n",
        "  y = softmax(Z)\n",
        "  return y\n",
        "\n",
        "def loss_cross(y, yest):\n",
        "  loss = - np.sum(y*np.log(yest)+(1-y)*np.log(1 - yest))/y.shape[0]\n",
        "  return loss\n",
        "\n",
        "def loss_mse (y, yest):\n",
        "  loss = np.sum((y-yest)*(y-yest))/y.shape[0]\n",
        "  return loss\n",
        "\n",
        "def loss_cc (y, yest): #catogorical cross entropy \n",
        "  loss = - np.sum(y*np.log(yest))/y.shape[0]\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHkVPEaSvSUs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 1:**\n",
        "***logistic regression with mean squared error loss***"
      ]
    },
    {
      "metadata": {
        "id": "q62H9HxXXZuW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_mse(X_train, Y_train, learning_rate, batch_size, parameter, epochs):\n",
        "  \n",
        "  W = parameter['W']\n",
        "  b = parameter['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]  \n",
        "\n",
        "      y_est = forward_pro(X, parameter)   \n",
        "\n",
        "      loss = loss_mse(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*y_est*(1-y_est)*(y_est - Y) # dZ = A'*(A-Y) for mean square error\n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameter['W'] = W\n",
        "      parameter['b'] = b  \n",
        "  \n",
        "  return parameter\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPLlDFcslC0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run ten individual one vs all classifier for mean square error\n",
        "Parameter = {}\n",
        "for i in range(10):\n",
        "  parameters = {'W' : np.zeros((X_train.shape[1], 1)),\n",
        "             'b': np.zeros(1)}\n",
        "  Y = (y_train == i).reshape(-1,1)*1\n",
        "  Parameter[i] = model_mse(X_train, Y, learning_rate = 0.001, batch_size = 40, parameter = parameters , epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usssWs-MPdIQ",
        "colab_type": "code",
        "outputId": "f563af7f-f4a5-4262-b120-b720dc295517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy for one vs all classifiers \n",
        "for i in range (10):\n",
        "  Y_est = (forward_pro(X_test, Parameter[i])>0.5)*1\n",
        "  acc = np.sum((Y_est == (y_test == i).reshape(-1,1))*1)/y_test.shape[0]\n",
        "  print (\"Accuracy for %d vs all: %f\" %(i, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0 vs all: 0.979300\n",
            "Accuracy for 1 vs all: 0.984200\n",
            "Accuracy for 2 vs all: 0.952600\n",
            "Accuracy for 3 vs all: 0.952900\n",
            "Accuracy for 4 vs all: 0.957300\n",
            "Accuracy for 5 vs all: 0.922400\n",
            "Accuracy for 6 vs all: 0.973200\n",
            "Accuracy for 7 vs all: 0.970800\n",
            "Accuracy for 8 vs all: 0.908000\n",
            "Accuracy for 9 vs all: 0.921600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FFCFSaIFmR7H",
        "colab_type": "code",
        "outputId": "3f098977-2033-4109-8b12-7b170c61c365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy of the overall classifiers using argmax \n",
        "\n",
        "Y_est = np.zeros((10000, 10))\n",
        "for i in range (10):\n",
        "  Y_est[:,i] = np.squeeze(forward_pro(X_test, Parameter[i]))\n",
        "   \n",
        "ara=np.argmax(Y_est, axis = 1) \n",
        "acc = np.sum(ara == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for the overall classifier using argmax: %f\" %acc)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the overall classifier using argmax: 0.838200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5UW4yrWreSN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pS2YVraR3hTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 2:**  ***logistic regression with binary cross entropy loss*** "
      ]
    },
    {
      "metadata": {
        "id": "dEWXJkSb3se-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_cross(X_train, Y_train, learning_rate, batch_size,parameters, epochs):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]\n",
        "      \n",
        "      y_est = forward_pro(X, parameters)   \n",
        "\n",
        "      loss = loss_cross(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*(y_est - Y) # dZ = A - Y for cross entropy loss\n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameters['W'] = W\n",
        "      parameters['b'] = b\n",
        "      \n",
        "  \n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnGVk4Vo3r-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run ten individual one vs all classifier for binary cross entropy loss\n",
        "Parameter = {}\n",
        "for i in range(10):\n",
        "  pmeter = {'W' : np.zeros((X_train.shape[1], 1)),\n",
        "             'b': np.zeros(1)}\n",
        "  Y = (y_train == i).reshape(-1,1)*1\n",
        "  Parameter[i] = model_cross(X_train, Y, learning_rate = 0.001, batch_size = 40, parameters = pmeter, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weLUXiHiFVIB",
        "colab_type": "code",
        "outputId": "45dc0a49-4b25-48fa-9b9b-7dd6bb114b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy for one vs all classifiers \n",
        "for i in range (10):\n",
        "  Y_est = (forward_pro(X_test, Parameter[i])>0.5)*1\n",
        "  acc = np.sum((Y_est == (y_test == i).reshape(-1,1))*1)/y_test.shape[0]\n",
        "  print (\"Accuracy for %d vs all: %f\" %(i, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0 vs all: 0.988400\n",
            "Accuracy for 1 vs all: 0.988700\n",
            "Accuracy for 2 vs all: 0.969800\n",
            "Accuracy for 3 vs all: 0.967400\n",
            "Accuracy for 4 vs all: 0.972400\n",
            "Accuracy for 5 vs all: 0.957100\n",
            "Accuracy for 6 vs all: 0.979700\n",
            "Accuracy for 7 vs all: 0.978700\n",
            "Accuracy for 8 vs all: 0.941100\n",
            "Accuracy for 9 vs all: 0.952000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pTQX_PB42FHl",
        "colab_type": "code",
        "outputId": "beecbce3-2c07-4de0-f115-f5d3b57df546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy of the overall classifiers using argmax \n",
        "\n",
        "Y_est = np.zeros((10000, 10))\n",
        "for i in range (10):\n",
        "  Y_est[:,i] = np.squeeze(forward_pro(X_test, Parameter[i]))\n",
        "   \n",
        "ara=np.argmax(Y_est, axis = 1) \n",
        "acc = np.sum(ara == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for the overall classifier using argmax: %f\" %acc)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the overall classifier using argmax: 0.882700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zalG8Sjy4oCt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 3:** ***softmax and categorical cross entropy loss***"
      ]
    },
    {
      "metadata": {
        "id": "DVCYDz6m4nak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_softmax(X_train, Y_train, learning_rate, batch_size, parameters, epochs):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]  \n",
        "\n",
        "      y_est = forward_softmax(X, parameters)   \n",
        "     \n",
        "      loss = loss_cc(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*(y_est - Y) \n",
        "      '''dzi = {ai - 1, if ith level is true. ai otherwise} \n",
        "      which vectorized as dZ = A-Y. dZ is divided by batch size for normalizing \n",
        "      '''  \n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameters['W'] = W\n",
        "      parameters['b'] = b     \n",
        "  \n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZjASYEAj7TbI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting labels(y) into one hot vector \n",
        "\n",
        "a = y_train\n",
        "Y = np.zeros((a.size, a.max()+1))\n",
        "Y[np.arange(a.size),a] = 1\n",
        "\n",
        "parameters_3 = {'W' : np.zeros((X_train.shape[1], 10)),\n",
        "             'b': np.zeros((1,10))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KaeIZhefIn0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Parameter = model_softmax(X_train, Y, learning_rate = 0.001, batch_size = 40, parameters = parameters_3, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrunrLyHQxIg",
        "colab_type": "code",
        "outputId": "4d70c0e1-1edf-49c5-bb76-406d783a2047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_est = forward_softmax(X_test, Parameter)\n",
        "Y_est = np.argmax(y_est, axis = 1)\n",
        "acc = np.sum(Y_est == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for softmax classifier: %f\" %acc)\n",
        "             "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for softmax classifier: 0.892400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vQZBxZTA7Uy7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 4:** ***Keras implementation ***"
      ]
    },
    {
      "metadata": {
        "id": "3bU8XL-6HtnX",
        "colab_type": "code",
        "outputId": "b9863a7a-e6b6-4cfa-ac8a-06f0cd0847f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(10, activation='softmax', input_shape=(28 * 28,)))\n",
        "network.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1SaMUnqiHtdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# preprocessing of dataset\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "X_test = x_test.reshape(x_test.shape[0], -1)/255\n",
        "\n",
        "a = y_train\n",
        "Y_train = np.zeros((a.size, a.max()+1))\n",
        "Y_train[np.arange(a.size),a] = 1\n",
        "Y_train = Y_train\n",
        "\n",
        "b = y_test\n",
        "Y_test = np.zeros((b.size, b.max()+1))\n",
        "Y_test[np.arange(b.size),b] = 1\n",
        "Y_test = Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHjE9097fSto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import sgd\n",
        "\n",
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drIBrxgAfzht",
        "colab_type": "code",
        "outputId": "654b14d2-45cf-4bfd-8016-4ce7f1dbaf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = network.fit(X_train, \n",
        "                      Y_train, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=40, \n",
        "                      validation_data=(X_test, Y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.8565 - acc: 0.7938 - val_loss: 0.5193 - val_acc: 0.8739\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.4860 - acc: 0.8745 - val_loss: 0.4236 - val_acc: 0.8882\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.4243 - acc: 0.8859 - val_loss: 0.3853 - val_acc: 0.8964\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3940 - acc: 0.8924 - val_loss: 0.3631 - val_acc: 0.9015\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3749 - acc: 0.8966 - val_loss: 0.3488 - val_acc: 0.9058\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3615 - acc: 0.9002 - val_loss: 0.3384 - val_acc: 0.9087\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3513 - acc: 0.9030 - val_loss: 0.3305 - val_acc: 0.9098\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3433 - acc: 0.9051 - val_loss: 0.3244 - val_acc: 0.9112\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.3368 - acc: 0.9063 - val_loss: 0.3200 - val_acc: 0.9112\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3310 - acc: 0.9079 - val_loss: 0.3144 - val_acc: 0.9127\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3266 - acc: 0.9088 - val_loss: 0.3109 - val_acc: 0.9141\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3225 - acc: 0.9102 - val_loss: 0.3079 - val_acc: 0.9161\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.3188 - acc: 0.9115 - val_loss: 0.3050 - val_acc: 0.9168\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.3156 - acc: 0.9121 - val_loss: 0.3027 - val_acc: 0.9161\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.3128 - acc: 0.9130 - val_loss: 0.3002 - val_acc: 0.9170\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3102 - acc: 0.9139 - val_loss: 0.2987 - val_acc: 0.9167\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.3079 - acc: 0.9141 - val_loss: 0.2970 - val_acc: 0.9180\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3057 - acc: 0.9150 - val_loss: 0.2954 - val_acc: 0.9182\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.3038 - acc: 0.9158 - val_loss: 0.2938 - val_acc: 0.9188\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.3019 - acc: 0.9164 - val_loss: 0.2924 - val_acc: 0.9192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p41OHz2xn4IH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5159aba-e7db-4963-bef5-c196356920c5"
      },
      "cell_type": "code",
      "source": [
        "network.evaluate(X_test, Y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 41us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2923765900492668, 0.9192]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "hpxYY-6PYWpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 5:** ***Add a new feature as number of white areas in each images ***"
      ]
    },
    {
      "metadata": {
        "id": "rL334eui_bIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting the images into binary images\n",
        "\n",
        "X_train = ((x_train/255)>0.5)*1\n",
        "X_test = ((x_test/255)>0.5)*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ipe7Xyzr_wE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DFS algorithm for finding out the number of white regions in each black and white images  "
      ]
    },
    {
      "metadata": {
        "id": "pXtAvsuH_a67",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adj = {'row' : [-1, -1, -1, 0, 0, 1, 1, 1],\n",
        "          'column' : [-1, 0, 1, -1, 1, -1, 0, 1]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nODMzWIe_anC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def DFS_visit(V, adj, x, y, parent):\n",
        "    r = adj['row']\n",
        "    c = adj['column']\n",
        "    for i in range (len(r)):\n",
        "        p = x+r[i]\n",
        "        q = y + c[i]\n",
        "        if p >= 0 and q >= 0 and p < V.shape[0] and q < V.shape[1]:\n",
        "            if V[p,q] == 0:\n",
        "                if (p,q) not in parent:\n",
        "                    parent [p,q] = (x,y)\n",
        "                    DFS_visit(V, adj, p, q, parent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BR7ICut_aag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def DFS (V, adj):\n",
        "    x, y = V.shape\n",
        "    white_area = 0\n",
        "    parent = {}\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if (i,j) not in parent:\n",
        "                parent [i,j] = None\n",
        "                if V[i,j] == 0:\n",
        "                    DFS_visit(V, adj, i,j, parent)\n",
        "                    white_area += 1\n",
        "    return white_area"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnDfCqahCYpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training dataset with extra feature \n",
        "\n",
        "white_area = np.zeros((X_train.shape[0],1))\n",
        "\n",
        "for i in range (X_train.shape[0]):\n",
        "  X = X_train[i]\n",
        "  white_area[i, 0] = DFS(X,adj)\n",
        "  \n",
        "X_train_dfs = x_train.reshape(x_train.shape[0], -1)/255\n",
        "\n",
        "X_train_dfs = np.append(X_train_dfs, white_area/3, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAe3Fxg0BcpF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test dataset with extra feature \n",
        "\n",
        "white_area_t = np.zeros((X_test.shape[0],1))\n",
        "\n",
        "for i in range (X_test.shape[0]):\n",
        "  X = X_test[i]\n",
        "  white_area_t[i, 0] = DFS(X,adj)\n",
        "  \n",
        "X_test_dfs = x_test.reshape(x_test.shape[0], -1)/255\n",
        "\n",
        "X_test_dfs = np.append(X_test_dfs, white_area_t/3, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQW9PPchaf0n",
        "colab_type": "code",
        "outputId": "2323eaca-2315-446a-df88-615f2c2a9327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train_dfs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "Y7FGC-FlAKt8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parameters_dfs = {'W' : np.zeros((X_train_dfs.shape[1], 10)),\n",
        "             'b': np.zeros((1,10))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nt_C84VDa3Rn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Parameter_dfs = model_softmax(X_train_dfs, Y, learning_rate = 0.001, batch_size = 40, parameters = parameters_dfs, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xe3gif5bYo3",
        "colab_type": "code",
        "outputId": "0fe66266-5265-45dc-fc6d-18781e88c7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_est = forward_softmax(X_test_dfs, Parameter_dfs)\n",
        "Y_est = np.argmax(y_est, axis = 1)\n",
        "acc = np.sum(Y_est == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for softmax classifier: %f\" %acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for softmax classifier: 0.895400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "70aS9u-ZbpyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}