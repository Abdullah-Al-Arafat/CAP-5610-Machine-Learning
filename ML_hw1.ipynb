{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_hw1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdullah-Al-Arafat/CAP-5610-Machine-Learning/blob/master/ML_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UswAAhVvXbXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CAP 5610: Machine Learning** \n",
        "Home work 1"
      ]
    },
    {
      "metadata": {
        "id": "3MZ9JQOWR7QM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7GNhBIHSlmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load MNIST dataset from keras and preprocess the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "X_test = x_test.reshape(x_test.shape[0], -1)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQWuW0VJvbp6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Necessary functions for forward and back propagation, and loss calculation"
      ]
    },
    {
      "metadata": {
        "id": "KOYVpZpGseAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid (x):\n",
        "  y = 1/(1 + np.exp(-x))\n",
        "  return y\n",
        "\n",
        "def softmax(Z):\n",
        "  return np.exp(Z)/np.sum(np.exp(Z), axis = 1, keepdims= True)\n",
        "\n",
        "def d_sigmoid (x):   # differentiation of sigmoid function \n",
        "  y = sigmoid(x)*(1-sigmoid(x))\n",
        "  return y\n",
        "\n",
        "def forward_pro(X,parameters):\n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  y = sigmoid(np.dot(X, W) + b)\n",
        "  return y\n",
        "\n",
        "def forward_softmax(X, parameters):\n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  Z = np.dot(X, W) + b\n",
        "  y = softmax(Z)\n",
        "  return y\n",
        "\n",
        "def loss_cross(y, yest):\n",
        "  loss = - np.sum(y*np.log(yest)+(1-y)*np.log(1 - yest))/y.shape[0]\n",
        "  return loss\n",
        "\n",
        "def loss_mse (y, yest):\n",
        "  loss = np.sum((y-yest)*(y-yest))/y.shape[0]\n",
        "  return loss\n",
        "\n",
        "def loss_cc (y, yest): #catogorical cross entropy \n",
        "  loss = - np.sum(y*np.log(yest))/y.shape[0]\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHkVPEaSvSUs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 1:**\n",
        "***logistic regression with mean squared error loss***"
      ]
    },
    {
      "metadata": {
        "id": "q62H9HxXXZuW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_mse(X_train, Y_train, learning_rate, batch_size, parameter, epochs):\n",
        "  \n",
        "  W = parameter['W']\n",
        "  b = parameter['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]  \n",
        "\n",
        "      y_est = forward_pro(X, parameter)   \n",
        "\n",
        "      loss = loss_mse(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*y_est*(1-y_est)*(y_est - Y) # dZ = A'*(A-Y) for mean square error\n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameter['W'] = W\n",
        "      parameter['b'] = b  \n",
        "  \n",
        "  return parameter\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPLlDFcslC0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run ten individual one vs all classifier for mean square error\n",
        "Parameter = {}\n",
        "for i in range(10):\n",
        "  parameters = {'W' : np.zeros((X_train.shape[1], 1)),\n",
        "             'b': np.zeros(1)}\n",
        "  Y = (y_train == i).reshape(-1,1)*1\n",
        "  Parameter[i] = model_mse(X_train, Y, learning_rate = 0.001, batch_size = 40, parameter = parameters , epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usssWs-MPdIQ",
        "colab_type": "code",
        "outputId": "22fc9022-a5aa-456b-c809-74c06334a84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy for one vs all classifiers \n",
        "for i in range (10):\n",
        "  Y_est = (forward_pro(X_test, Parameter[i])>0.5)*1\n",
        "  acc = np.sum((Y_est == (y_test == i).reshape(-1,1))*1)/y_test.shape[0]\n",
        "  print (\"Accuracy for %d vs all: %f\" %(i, acc))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0 vs all: 0.979300\n",
            "Accuracy for 1 vs all: 0.984200\n",
            "Accuracy for 2 vs all: 0.952600\n",
            "Accuracy for 3 vs all: 0.953100\n",
            "Accuracy for 4 vs all: 0.957300\n",
            "Accuracy for 5 vs all: 0.922500\n",
            "Accuracy for 6 vs all: 0.973100\n",
            "Accuracy for 7 vs all: 0.970700\n",
            "Accuracy for 8 vs all: 0.908100\n",
            "Accuracy for 9 vs all: 0.921700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FFCFSaIFmR7H",
        "colab_type": "code",
        "outputId": "261fad89-7b00-40e5-c1d8-f7168c189dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy of the overall classifiers using argmax \n",
        "\n",
        "Y_est = np.zeros((10000, 10))\n",
        "for i in range (10):\n",
        "  Y_est[:,i] = np.squeeze(forward_pro(X_test, Parameter[i]))\n",
        "   \n",
        "ara=np.argmax(Y_est, axis = 1) \n",
        "acc = np.sum(ara == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for the overall classifier using argmax: %f\" %acc)  \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the overall classifier using argmax: 0.838400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5UW4yrWreSN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pS2YVraR3hTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 2:**  ***logistic regression with binary cross entropy loss*** "
      ]
    },
    {
      "metadata": {
        "id": "dEWXJkSb3se-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_cross(X_train, Y_train, learning_rate, batch_size,parameters, epochs):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]\n",
        "      \n",
        "      y_est = forward_pro(X, parameters)   \n",
        "\n",
        "      loss = loss_cross(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*(y_est - Y) # dZ = A - Y for cross entropy loss\n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameters['W'] = W\n",
        "      parameters['b'] = b\n",
        "      \n",
        "  \n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnGVk4Vo3r-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run ten individual one vs all classifier for binary cross entropy loss\n",
        "Parameter = {}\n",
        "for i in range(10):\n",
        "  pmeter = {'W' : np.zeros((X_train.shape[1], 1)),\n",
        "             'b': np.zeros(1)}\n",
        "  Y = (y_train == i).reshape(-1,1)*1\n",
        "  Parameter[i] = model_cross(X_train, Y, learning_rate = 0.001, batch_size = 40, parameters = pmeter, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weLUXiHiFVIB",
        "colab_type": "code",
        "outputId": "ea5c520a-68c5-47e0-83d9-58503da0db2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy for one vs all classifiers \n",
        "for i in range (10):\n",
        "  Y_est = (forward_pro(X_test, Parameter[i])>0.5)*1\n",
        "  acc = np.sum((Y_est == (y_test == i).reshape(-1,1))*1)/y_test.shape[0]\n",
        "  print (\"Accuracy for %d vs all: %f\" %(i, acc))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0 vs all: 0.988400\n",
            "Accuracy for 1 vs all: 0.988600\n",
            "Accuracy for 2 vs all: 0.969800\n",
            "Accuracy for 3 vs all: 0.967000\n",
            "Accuracy for 4 vs all: 0.972400\n",
            "Accuracy for 5 vs all: 0.957100\n",
            "Accuracy for 6 vs all: 0.979600\n",
            "Accuracy for 7 vs all: 0.978600\n",
            "Accuracy for 8 vs all: 0.940600\n",
            "Accuracy for 9 vs all: 0.951800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pTQX_PB42FHl",
        "colab_type": "code",
        "outputId": "e331a9eb-48a5-44a5-cab3-7826ad2ed182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy of the overall classifiers using argmax \n",
        "\n",
        "Y_est = np.zeros((10000, 10))\n",
        "for i in range (10):\n",
        "  Y_est[:,i] = np.squeeze(forward_pro(X_test, Parameter[i]))\n",
        "   \n",
        "ara=np.argmax(Y_est, axis = 1) \n",
        "acc = np.sum(ara == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for the overall classifier using argmax: %f\" %acc)  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the overall classifier using argmax: 0.882800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zalG8Sjy4oCt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 3:** ***softmax and categorical cross entropy loss***"
      ]
    },
    {
      "metadata": {
        "id": "DVCYDz6m4nak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_softmax(X_train, Y_train, learning_rate, batch_size, parameters, epochs):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  m = X_train.shape[0] # number of samples in training set\n",
        "  \n",
        "  for j in range (epochs):\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_shuffled = X_train[shuffled_indices]\n",
        "    y_shuffled = Y_train[shuffled_indices]\n",
        "    \n",
        "    for i in range(0, m, batch_size):\n",
        "      \n",
        "      X = X_shuffled[i : i + batch_size]\n",
        "      Y = y_shuffled[i : i + batch_size]  \n",
        "\n",
        "      y_est = forward_softmax(X, parameters)   \n",
        "     \n",
        "      loss = loss_cc(Y, y_est)\n",
        "      \n",
        "      dZ = (1/batch_size)*(y_est - Y) \n",
        "      '''dzi = {ai - 1, if ith level is true. ai otherwise} \n",
        "      which vectorized as dZ = A-Y. dZ is divided by batch size for normalizing \n",
        "      '''  \n",
        "      dW = np.dot(X.T, dZ)\n",
        "      db = np.sum(dZ)      \n",
        "\n",
        "      W = W - learning_rate*dW\n",
        "      b = b -learning_rate*db\n",
        "      \n",
        "      parameters['W'] = W\n",
        "      parameters['b'] = b     \n",
        "  \n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZjASYEAj7TbI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting labels(y) into one hot vector \n",
        "\n",
        "a = y_train\n",
        "Y = np.zeros((a.size, a.max()+1))\n",
        "Y[np.arange(a.size),a] = 1\n",
        "\n",
        "parameters_3 = {'W' : np.zeros((X_train.shape[1], 10)),\n",
        "             'b': np.zeros((1,10))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KaeIZhefIn0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Parameter = model_softmax(X_train, Y, learning_rate = 0.001, batch_size = 40, parameters = parameters_3, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrunrLyHQxIg",
        "colab_type": "code",
        "outputId": "b92e5745-d6f5-45de-d40d-a878ae4eb51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_est = forward_softmax(X_test, Parameter)\n",
        "Y_est = np.argmax(y_est, axis = 1)\n",
        "acc = np.sum(Y_est == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for softmax classifier: %f\" %acc)\n",
        "             "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for softmax classifier: 0.892300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vQZBxZTA7Uy7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 4:** ***Keras implementation ***"
      ]
    },
    {
      "metadata": {
        "id": "3bU8XL-6HtnX",
        "colab_type": "code",
        "outputId": "390b24a9-360c-4adb-aa86-e54e766e2623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(10, activation='softmax', input_shape=(28 * 28,)))\n",
        "network.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1SaMUnqiHtdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# preprocessing of dataset\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], -1)/255\n",
        "X_test = x_test.reshape(x_test.shape[0], -1)/255\n",
        "\n",
        "a = y_train\n",
        "Y_train = np.zeros((a.size, a.max()+1))\n",
        "Y_train[np.arange(a.size),a] = 1\n",
        "Y_train = Y_train\n",
        "\n",
        "b = y_test\n",
        "Y_test = np.zeros((b.size, b.max()+1))\n",
        "Y_test[np.arange(b.size),b] = 1\n",
        "Y_test = Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHjE9097fSto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import sgd\n",
        "\n",
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drIBrxgAfzht",
        "colab_type": "code",
        "outputId": "c2a1b29d-d3b3-4303-b578-de1c5c48070a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = network.fit(X_train, \n",
        "                      Y_train, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=40, \n",
        "                      validation_data=(X_test, Y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.8334 - acc: 0.8054 - val_loss: 0.5141 - val_acc: 0.8766\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.4838 - acc: 0.8753 - val_loss: 0.4222 - val_acc: 0.8893\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.4234 - acc: 0.8871 - val_loss: 0.3841 - val_acc: 0.8979\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3934 - acc: 0.8932 - val_loss: 0.3627 - val_acc: 0.9021\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3745 - acc: 0.8968 - val_loss: 0.3485 - val_acc: 0.9066\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3612 - acc: 0.9002 - val_loss: 0.3378 - val_acc: 0.9096\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.3511 - acc: 0.9024 - val_loss: 0.3310 - val_acc: 0.9103\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.3432 - acc: 0.9046 - val_loss: 0.3232 - val_acc: 0.9123\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.3366 - acc: 0.9060 - val_loss: 0.3191 - val_acc: 0.9125\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.3312 - acc: 0.9080 - val_loss: 0.3138 - val_acc: 0.9137\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.3264 - acc: 0.9092 - val_loss: 0.3102 - val_acc: 0.9146\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.3223 - acc: 0.9099 - val_loss: 0.3076 - val_acc: 0.9162\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.3187 - acc: 0.9114 - val_loss: 0.3047 - val_acc: 0.9159\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.3155 - acc: 0.9121 - val_loss: 0.3026 - val_acc: 0.9174\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.3127 - acc: 0.9138 - val_loss: 0.2999 - val_acc: 0.9178\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.3102 - acc: 0.9143 - val_loss: 0.2976 - val_acc: 0.9189\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.3078 - acc: 0.9146 - val_loss: 0.2966 - val_acc: 0.9175\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.3057 - acc: 0.9150 - val_loss: 0.2945 - val_acc: 0.9196\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.3037 - acc: 0.9155 - val_loss: 0.2934 - val_acc: 0.9185\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.3018 - acc: 0.9165 - val_loss: 0.2917 - val_acc: 0.9192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p41OHz2xn4IH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "83405e8d-6474-4f45-9368-ffb7317c76f9"
      },
      "cell_type": "code",
      "source": [
        "network.evaluate(X_test, Y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 46us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2917178484618664, 0.9192]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "hpxYY-6PYWpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 5:** ***Add a new feature as number of white areas in each images ***"
      ]
    },
    {
      "metadata": {
        "id": "rL334eui_bIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting the images into binary images\n",
        "\n",
        "X_train = ((x_train/255)>0.5)*1\n",
        "X_test = ((x_test/255)>0.5)*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ipe7Xyzr_wE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DFS algorithm for finding out the number of white regions in each black and white images  "
      ]
    },
    {
      "metadata": {
        "id": "pXtAvsuH_a67",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adj = {'row' : [-1, -1, -1, 0, 0, 1, 1, 1],\n",
        "          'column' : [-1, 0, 1, -1, 1, -1, 0, 1]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nODMzWIe_anC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def DFS_visit(V, adj, x, y, parent):\n",
        "    r = adj['row']\n",
        "    c = adj['column']\n",
        "    for i in range (len(r)):\n",
        "        p = x+r[i]\n",
        "        q = y + c[i]\n",
        "        if p >= 0 and q >= 0 and p < V.shape[0] and q < V.shape[1]:\n",
        "            if V[p,q] == 0:\n",
        "                if (p,q) not in parent:\n",
        "                    parent [p,q] = (x,y)\n",
        "                    DFS_visit(V, adj, p, q, parent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BR7ICut_aag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def DFS (V, adj):\n",
        "    x, y = V.shape\n",
        "    white_area = 0\n",
        "    parent = {}\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if (i,j) not in parent:\n",
        "                parent [i,j] = None\n",
        "                if V[i,j] == 0:\n",
        "                    DFS_visit(V, adj, i,j, parent)\n",
        "                    white_area += 1\n",
        "    return white_area"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnDfCqahCYpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training dataset with extra feature \n",
        "\n",
        "white_area = np.zeros((X_train.shape[0],1))\n",
        "\n",
        "for i in range (X_train.shape[0]):\n",
        "  X = X_train[i]\n",
        "  white_area[i, 0] = DFS(X,adj)\n",
        "  \n",
        "X_train_dfs = x_train.reshape(x_train.shape[0], -1)/255\n",
        "\n",
        "X_train_dfs = np.append(X_train_dfs, white_area/3, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAe3Fxg0BcpF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test dataset with extra feature \n",
        "\n",
        "white_area_t = np.zeros((X_test.shape[0],1))\n",
        "\n",
        "for i in range (X_test.shape[0]):\n",
        "  X = X_test[i]\n",
        "  white_area_t[i, 0] = DFS(X,adj)\n",
        "  \n",
        "X_test_dfs = x_test.reshape(x_test.shape[0], -1)/255\n",
        "\n",
        "X_test_dfs = np.append(X_test_dfs, white_area_t/3, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQW9PPchaf0n",
        "colab_type": "code",
        "outputId": "eabc95f0-242a-40e4-f116-367ba58814e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train_dfs.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "Y7FGC-FlAKt8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parameters_dfs = {'W' : np.zeros((X_train_dfs.shape[1], 10)),\n",
        "             'b': np.zeros((1,10))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nt_C84VDa3Rn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Parameter_dfs = model_softmax(X_train_dfs, Y, learning_rate = 0.001, batch_size = 40, parameters = parameters_dfs, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xe3gif5bYo3",
        "colab_type": "code",
        "outputId": "d078f6cf-d790-455d-82a2-dcd51308f86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_est = forward_softmax(X_test_dfs, Parameter_dfs)\n",
        "Y_est = np.argmax(y_est, axis = 1)\n",
        "acc = np.sum(Y_est == y_test)/y_test.shape[0]\n",
        "\n",
        "print (\"Accuracy for softmax classifier: %f\" %acc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for softmax classifier: 0.895600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "70aS9u-ZbpyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}